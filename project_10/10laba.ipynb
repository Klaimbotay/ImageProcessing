{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10laba.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGqbKpgd4PBP",
        "outputId": "6cedd127-7304-44ef-cb91-c3feca472518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joCBQ5uf-U7B",
        "outputId": "54130064-c056-40cf-8dd5-30f019f966cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "n_samples, batch_size, num_steps = 1000, 109, 1000\n",
        "# Создаем 1000 случайных равномерно распределенных точек:\n",
        "X_data = np.random.uniform(1, 10, (n_samples,1))\n",
        "# Находим для каждого x «правильный ответ»\n",
        "y_data = 14 * X_data + 9 + np.random.uniform(-1, 1, (n_samples,1))\n",
        "X = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "y = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "print(tf.random_normal((1,1)))\n",
        "print(tf.zeros((1,)))\n",
        "with tf.variable_scope('linear-regression'):\n",
        "  k = tf.Variable(tf.random_normal((1,1)), name='slope')\n",
        "  b = tf.Variable(tf.zeros((1,)), name='bias')\n",
        "# tf.matmul требует на вход только матрицы (даже если 1х1),\n",
        "# складывать далее можно и с обычным вектором\n",
        "y_pred = tf.matmul(X, k) + b\n",
        "# tf.reduce_sum считает сумму матрицы по строкам\n",
        "loss = tf.reduce_sum((y - y_pred) ** 2)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)\n",
        "display_step = 100\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(num_steps):\n",
        "    indices = np.random.choice(n_samples, batch_size)\n",
        "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
        "    _, loss_val, k_val, b_val = sess.run([optimizer, loss, k, b], feed_dict = {X: X_batch, y: y_batch})\n",
        "    if (i+1) % display_step == 0:\n",
        "      print('Эпоха %d: %.8f, k=%.4f, b=%.4f' % (i+1, loss_val, k_val, b_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"random_normal_3:0\", shape=(1, 1), dtype=float32)\n",
            "Tensor(\"zeros_3:0\", shape=(1,), dtype=float32)\n",
            "Эпоха 100: 513.81390381, k=14.6653, b=4.4765\n",
            "Эпоха 200: 252.44764709, k=14.4544, b=5.9591\n",
            "Эпоха 300: 113.65302277, k=14.2797, b=6.9781\n",
            "Эпоха 400: 89.89701080, k=14.1905, b=7.6646\n",
            "Эпоха 500: 47.51282120, k=14.1456, b=8.1153\n",
            "Эпоха 600: 43.13819885, k=14.0941, b=8.4199\n",
            "Эпоха 700: 35.35462189, k=14.0610, b=8.6130\n",
            "Эпоха 800: 42.42478943, k=14.0445, b=8.7576\n",
            "Эпоха 900: 32.61532593, k=14.0232, b=8.8440\n",
            "Эпоха 1000: 29.68955803, k=14.0232, b=8.9068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH3i-GPYE1cP",
        "outputId": "2056b420-9bbb-4a52-a369-80c4fd0bf635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "n_samples, batch_size, num_steps = 500, 100, 700\n",
        "# Создаем 1000 случайных равномерно распределенных точек:\n",
        "X_data = np.random.uniform(1, 10, (n_samples,1))\n",
        "# Находим для каждого x «правильный ответ»\n",
        "y_data = 14 * X_data + 9 + np.random.uniform(-1, 1, (n_samples,1))\n",
        "X = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "y = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "print(tf.random_normal((1,1)))\n",
        "print(tf.zeros((1,)))\n",
        "with tf.variable_scope('linear-regression'):\n",
        "  k = tf.Variable(tf.random_normal((1,1)), name='slope')\n",
        "  b = tf.Variable(tf.zeros((1,)), name='bias')\n",
        "# tf.matmul требует на вход только матрицы (даже если 1х1),\n",
        "# складывать далее можно и с обычным вектором\n",
        "y_pred = tf.matmul(X, k) + b\n",
        "# tf.reduce_sum считает сумму матрицы по строкам\n",
        "loss = tf.reduce_sum((y - y_pred) ** 2)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)\n",
        "display_step = 100\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(num_steps):\n",
        "    indices = np.random.choice(n_samples, batch_size)\n",
        "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
        "    _, loss_val, k_val, b_val = sess.run([optimizer, loss, k, b], feed_dict = {X: X_batch, y: y_batch})\n",
        "    if (i+1) % display_step == 0:\n",
        "      print('Эпоха %d: %.8f, k=%.4f, b=%.4f' % (i+1, loss_val, k_val, b_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"random_normal_24:0\", shape=(1, 1), dtype=float32)\n",
            "Tensor(\"zeros_23:0\", shape=(1,), dtype=float32)\n",
            "Эпоха 100: 454.36587524, k=14.7777, b=4.5828\n",
            "Эпоха 200: 243.95654297, k=14.5232, b=6.0873\n",
            "Эпоха 300: 117.89754486, k=14.3634, b=7.1412\n",
            "Эпоха 400: 70.36436462, k=14.2513, b=7.8867\n",
            "Эпоха 500: 31.06023598, k=14.1549, b=8.3877\n",
            "Эпоха 600: 20.10727501, k=14.1195, b=8.7302\n",
            "Эпоха 700: 14.14725685, k=14.0801, b=8.9685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3k_K7fFE7O8",
        "outputId": "e6ea0b76-6149-42a6-d080-53f4c96d4288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "n_samples, batch_size, num_steps = 250, 100, 750\n",
        "# Создаем 1000 случайных равномерно распределенных точек:\n",
        "X_data = np.random.uniform(1, 10, (n_samples,1))\n",
        "# Находим для каждого x «правильный ответ»\n",
        "y_data = 14 * X_data + 9 + np.random.uniform(0, 1, (n_samples,1))\n",
        "X = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "y = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "print(tf.random_normal((1,1)))\n",
        "print(tf.zeros((1,)))\n",
        "with tf.variable_scope('linear-regression'):\n",
        "  k = tf.Variable(tf.random_normal((1,1)), name='slope')\n",
        "  b = tf.Variable(tf.zeros((1,)), name='bias')\n",
        "# tf.matmul требует на вход только матрицы (даже если 1х1),\n",
        "# складывать далее можно и с обычным вектором\n",
        "y_pred = tf.matmul(X, k) + b\n",
        "# tf.reduce_sum считает сумму матрицы по строкам\n",
        "loss = tf.reduce_sum((y - y_pred) ** 2)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)\n",
        "display_step = 100\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(num_steps):\n",
        "    indices = np.random.choice(n_samples, batch_size)\n",
        "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
        "    _, loss_val, k_val, b_val = sess.run([optimizer, loss, k, b], feed_dict = {X: X_batch, y: y_batch})\n",
        "    if (i+1) % display_step == 0:\n",
        "      print('Эпоха %d: %.8f, k=%.4f, b=%.4f' % (i+1, loss_val, k_val, b_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"random_normal_25:0\", shape=(1, 1), dtype=float32)\n",
            "Tensor(\"zeros_24:0\", shape=(1,), dtype=float32)\n",
            "Эпоха 100: 450.70596313, k=14.7994, b=4.3386\n",
            "Эпоха 200: 299.75274658, k=14.5794, b=5.8902\n",
            "Эпоха 300: 135.31912231, k=14.3869, b=6.9785\n",
            "Эпоха 400: 68.13999939, k=14.2680, b=7.7461\n",
            "Эпоха 500: 31.17311668, k=14.1921, b=8.2846\n",
            "Эпоха 600: 20.13479805, k=14.1326, b=8.6699\n",
            "Эпоха 700: 13.91827202, k=14.0894, b=8.9429\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}